<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8" ></meta>
        <title>kafka/kafka/log/LogCleanerManager.scala</title>
        <script type="text/javascript" src="../../../jquery-all.js"></script>
        <script type="text/javascript" src="../../../linked.js"></script>
        <link rel="stylesheet" type="text/css" href="../../../style.css" title="Style"></link>
    </head>
    <body>
        <pre>
<span class="comment">/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the &quot;License&quot;); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */</span>

package kafka.log

import java.io.File
import kafka.metrics.KafkaMetricsGroup
import com.yammer.metrics.core.Gauge
import kafka.utils.<span class="delimiter">{</span>Logging, Pool<span class="delimiter">}</span>
import kafka.server.OffsetCheckpoint
import collection.mutable
import java.util.concurrent.locks.ReentrantLock
import kafka.utils.<a href="../utils/Utils.scala.html#kafka.utils.Utils" title="kafka.utils.Utils.type">Utils</a>._
import java.util.concurrent.TimeUnit
import kafka.common.<span class="delimiter">{</span>LogCleaningAbortedException, TopicAndPartition<span class="delimiter">}</span>

private<span class="delimiter">[</span>log<span class="delimiter">]</span> sealed trait <a title="trait LogCleaningState extends AnyRef" id="kafka.log;LogCleaningState">LogCleaningState</a>
private<span class="delimiter">[</span>log<span class="delimiter">]</span> case object <a href="#kafka.log.LogCleaningInProgress.productElement.x$1" title="kafka.log.LogCleaningInProgress.type" id="kafka.log.LogCleaningInProgress.readResolve">LogCleaningInProgress</a> extends <a href="#kafka.log;LogCleaningState" title="kafka.log.LogCleaningState">LogCleaningState</a>
private<span class="delimiter">[</span>log<span class="delimiter">]</span> case object <a href="#kafka.log.LogCleaningAborted.productElement.x$1" title="kafka.log.LogCleaningAborted.type" id="kafka.log.LogCleaningAborted.readResolve">LogCleaningAborted</a> extends <a href="#kafka.log;LogCleaningState" title="kafka.log.LogCleaningState">LogCleaningState</a>
private<span class="delimiter">[</span>log<span class="delimiter">]</span> case object <a href="#kafka.log.LogCleaningPaused.productElement.x$1" title="kafka.log.LogCleaningPaused.type" id="kafka.log.LogCleaningPaused.readResolve">LogCleaningPaused</a> extends <a href="#kafka.log;LogCleaningState" title="kafka.log.LogCleaningState">LogCleaningState</a>

<span class="comment">/**
 *  Manage the state of each partition being cleaned.
 *  If a partition is to be cleaned, it enters the LogCleaningInProgress state.
 *  While a partition is being cleaned, it can be requested to be aborted and paused. Then the partition first enters
 *  the LogCleaningAborted state. Once the cleaning task is aborted, the partition enters the LogCleaningPaused state.
 *  While a partition is in the LogCleaningPaused state, it won't be scheduled for cleaning again, until cleaning is
 *  requested to be resumed.
 */</span>
private<span class="delimiter">[</span>log<span class="delimiter">]</span> class <a title="class LogCleanerManager extends AnyRef with kafka.utils.Logging with kafka.metrics.KafkaMetricsGroup" id="kafka.log;LogCleanerManager">LogCleanerManager</a><a href="#kafka.log;LogCleanerManager" title="kafka.log.LogCleanerManager" class="delimiter">(</a>val <a title="Array[java.io.File]" id="kafka.log;LogCleanerManager.logDirs">logDirs</a>: <span title="Array[java.io.File]">Array</span><span class="delimiter">[</span>File<span class="delimiter">]</span>, val <a title="kafka.utils.Pool[kafka.common.TopicAndPartition,kafka.log.Log]" id="kafka.log;LogCleanerManager.logs">logs</a>: <a href="../utils/Pool.scala.html#kafka.utils;Pool" title="kafka.utils.Pool[kafka.common.TopicAndPartition,kafka.log.Log]">Pool</a><span class="delimiter">[</span>TopicAndPartition, Log<span class="delimiter">]</span><span class="delimiter">)</span> extends <a href="../utils/Logging.scala.html#kafka.utils;Logging" title="kafka.utils.Logging">Logging</a> with <a href="../metrics/KafkaMetricsGroup.scala.html#kafka.metrics;KafkaMetricsGroup" title="kafka.metrics.KafkaMetricsGroup">KafkaMetricsGroup</a> <span class="delimiter">{</span>
  
  override val <a title="String" id="kafka.log;LogCleanerManager.loggerName">loggerName</a> = classOf<span title="Class[kafka.log.LogCleaner](classOf[kafka.log.LogCleaner])" class="delimiter">[</span>LogCleaner<span class="delimiter">]</span>.<span title="()String">getName</span>

  <span class="comment">// package-private for testing</span>
  private<span class="delimiter">[</span>log<span class="delimiter">]</span> val <a title="String" id="kafka.log;LogCleanerManager.offsetCheckpointFile">offsetCheckpointFile</a> = <span title="String(&quot;cleaner-offset-checkpoint&quot;)" class="string">&quot;cleaner-offset-checkpoint&quot;</span>
  
  <span class="comment">/* the offset checkpoints holding the last cleaned point for each log */</span>
  private val <a title="scala.collection.immutable.Map[java.io.File,kafka.server.OffsetCheckpoint]" id="kafka.log;LogCleanerManager.checkpoints">checkpoints</a> = <a href="#kafka.log;LogCleanerManager.logDirs" title="(xs: Array[java.io.File])scala.collection.mutable.ArrayOps[java.io.File]">logDirs</a>.<span title="(f: java.io.File =&gt; (java.io.File, kafka.server.OffsetCheckpoint))(implicit bf: scala.collection.generic.CanBuildFrom[Array[java.io.File],(java.io.File, kafka.server.OffsetCheckpoint),Array[(java.io.File, kafka.server.OffsetCheckpoint)]])Array[(java.io.File, kafka.server.OffsetCheckpoint)]">map</span><span title="(xs: Array[(java.io.File, kafka.server.OffsetCheckpoint)])scala.collection.mutable.ArrayOps[(java.io.File, kafka.server.OffsetCheckpoint)]" class="delimiter">(</span><a title="java.io.File" id="kafka.log;LogCleanerManager.checkpoints.$anonfun.dir">dir</a> =&gt; <span title="(_1: java.io.File, _2: kafka.server.OffsetCheckpoint)(java.io.File, kafka.server.OffsetCheckpoint)" class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.checkpoints.$anonfun.dir" title="java.io.File">dir</a>, new <a href="../server/OffsetCheckpoint.scala.html#kafka.server;OffsetCheckpoint" title="kafka.server.OffsetCheckpoint">OffsetCheckpoint</a><span class="delimiter">(</span>new <span title="java.io.File">File</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.checkpoints.$anonfun.dir" title="java.io.File">dir</a>, <a href="#kafka.log;LogCleanerManager.offsetCheckpointFile" title="=&gt; String">offsetCheckpointFile</a><span class="delimiter">)</span><span class="delimiter">)</span><span class="delimiter">)</span><span class="delimiter">)</span>.<span title="(implicit ev: &lt;:&lt;[(java.io.File, kafka.server.OffsetCheckpoint),(java.io.File, kafka.server.OffsetCheckpoint)])scala.collection.immutable.Map[java.io.File,kafka.server.OffsetCheckpoint]">toMap</span>

  <span class="comment">/* the set of logs currently being cleaned */</span>
  private val <a title="scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]" id="kafka.log;LogCleanerManager.inProgress">inProgress</a> = mutable.<span title="[A, B](elems: (A, B)*)scala.collection.mutable.HashMap[A,B]">HashMap</span><span title="(elems: (kafka.common.TopicAndPartition, kafka.log.LogCleaningState)*)scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]" class="delimiter">[</span><a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a>, <a href="#kafka.log;LogCleaningState" title="kafka.log.LogCleaningState">LogCleaningState</a><span class="delimiter">]</span><span class="delimiter">(</span><span class="delimiter">)</span>

  <span class="comment">/* a global lock used to control all access to the in-progress set and the offset checkpoints */</span>
  private val <a title="java.util.concurrent.locks.ReentrantLock" id="kafka.log;LogCleanerManager.lock">lock</a> = new <span title="java.util.concurrent.locks.ReentrantLock">ReentrantLock</span>
  
  <span class="comment">/* for coordinating the pausing and the cleaning of a partition */</span>
  private val <a title="java.util.concurrent.locks.Condition" id="kafka.log;LogCleanerManager.pausedCleaningCond">pausedCleaningCond</a> = <a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a>.<span title="()java.util.concurrent.locks.Condition">newCondition</span><span class="delimiter">(</span><span class="delimiter">)</span>
  
  <span class="comment">/* a gauge for tracking the cleanable ratio of the dirtiest log */</span>
  @volatile private var <a title="Double" id="kafka.log;LogCleanerManager.dirtiestLogCleanableRatio_=">dirtiestLogCleanableRatio</a> = <span title="Double(0.0)" class="double">0.0</span>
  <a href="../metrics/KafkaMetricsGroup.scala.html#kafka.metrics;KafkaMetricsGroup.newGauge" title="(name: String, metric: com.yammer.metrics.core.Gauge[Int], tags: scala.collection.Map[String,String])com.yammer.metrics.core.Gauge[Int]">newGauge</a><span class="delimiter">(</span><span title="String(&quot;max-dirty-percent&quot;)" class="string">&quot;max-dirty-percent&quot;</span>, new <a title="&lt;$anon: com.yammer.metrics.core.Gauge[Int]&gt; extends com.yammer.metrics.core.Gauge[Int]" id="kafka.log;LogCleanerManager.<local LogCleanerManager>;$anon">Gauge</a><span class="delimiter">[</span>Int<span class="delimiter">]</span> <span class="delimiter">{</span> def <a title="()Int" id="kafka.log;LogCleanerManager.<local LogCleanerManager>;$anon.value">value</a> = <span class="delimiter">(</span><span title="Int(100)" class="int">100</span> <span title="(x: Double)Double">*</span> <a href="#kafka.log;LogCleanerManager.dirtiestLogCleanableRatio_=" title="=&gt; Double">dirtiestLogCleanableRatio</a><span class="delimiter">)</span>.<span title="=&gt; Int">toInt</span> <span class="delimiter">}</span><span class="delimiter">)</span>

  <span class="comment">/**
   * @return the position processed for all logs.
   */</span>
  def <a title="()Map[kafka.common.TopicAndPartition,Long]" id="kafka.log;LogCleanerManager.allCleanerCheckpoints">allCleanerCheckpoints</a><span class="delimiter">(</span><span class="delimiter">)</span>: <span title="Map[kafka.common.TopicAndPartition,Long]">Map</span><span class="delimiter">[</span>TopicAndPartition, Long<span class="delimiter">]</span> =
    <a href="#kafka.log;LogCleanerManager.checkpoints" title="=&gt; scala.collection.immutable.Map[java.io.File,kafka.server.OffsetCheckpoint]">checkpoints</a>.<span title="=&gt; Iterable[kafka.server.OffsetCheckpoint]">values</span>.<span title="(f: kafka.server.OffsetCheckpoint =&gt; scala.collection.GenTraversableOnce[(kafka.common.TopicAndPartition, Long)])(implicit bf: scala.collection.generic.CanBuildFrom[Iterable[kafka.server.OffsetCheckpoint],(kafka.common.TopicAndPartition, Long),Iterable[(kafka.common.TopicAndPartition, Long)]])Iterable[(kafka.common.TopicAndPartition, Long)]">flatMap</span><span title="scala.collection.generic.CanBuildFrom[scala.collection.Iterable.Coll,(kafka.common.TopicAndPartition, Long),Iterable[(kafka.common.TopicAndPartition, Long)]]" class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.allCleanerCheckpoints.$anonfun.x$1" title="kafka.server.OffsetCheckpoint">_</a>.<a href="../server/OffsetCheckpoint.scala.html#kafka.server;OffsetCheckpoint.read" title="()scala.collection.Map[kafka.common.TopicAndPartition,Long]">read</a><span class="delimiter">(</span><span class="delimiter">)</span><span class="delimiter">)</span>.<span title="(implicit ev: &lt;:&lt;[(kafka.common.TopicAndPartition, Long),(kafka.common.TopicAndPartition, Long)])scala.collection.immutable.Map[kafka.common.TopicAndPartition,Long]">toMap</span>

   <span class="comment">/**
    * Choose the log to clean next and add it to the in-progress set. We recompute this
    * every time off the full set of logs to allow logs to be dynamically added to the pool of logs
    * the log manager maintains.
    */</span>
  def <a title="()Option[kafka.log.LogToClean]" id="kafka.log;LogCleanerManager.grabFilthiestLog">grabFilthiestLog</a><span class="delimiter">(</span><span class="delimiter">)</span>: <span title="Option[kafka.log.LogToClean]">Option</span><span class="delimiter">[</span>LogToClean<span class="delimiter">]</span> = <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Option[kafka.log.LogToClean])Option[kafka.log.LogToClean]">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span class="delimiter">{</span>
      val <a title="Map[kafka.common.TopicAndPartition,Long]" id="kafka.log;LogCleanerManager.grabFilthiestLog.lastClean">lastClean</a> = <a href="#kafka.log;LogCleanerManager.allCleanerCheckpoints" title="()Map[kafka.common.TopicAndPartition,Long]">allCleanerCheckpoints</a><span class="delimiter">(</span><span class="delimiter">)</span>
      val <a title="Iterable[kafka.log.LogToClean]" id="kafka.log;LogCleanerManager.grabFilthiestLog.dirtyLogs">dirtyLogs</a> = <a href="#kafka.log;LogCleanerManager.logs" title="=&gt; kafka.utils.Pool[kafka.common.TopicAndPartition,kafka.log.Log]">logs</a>.<span title="(p: ((kafka.common.TopicAndPartition, kafka.log.Log)) =&gt; Boolean)Iterable[(kafka.common.TopicAndPartition, kafka.log.Log)]">filter</span><span class="delimiter">(</span><span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span> =&gt; <span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span>.<span title="=&gt; kafka.log.Log">_2</span>.<a href="Log.scala.html#kafka.log;Log.config" title="=&gt; kafka.log.LogConfig">config</a>.<a href="LogConfig.scala.html#kafka.log;LogConfig.compact" title="=&gt; Boolean">compact</a><span class="delimiter">)</span>          <span class="comment">// skip any logs marked for delete rather than dedupe</span>
                          .<span title="(p: ((kafka.common.TopicAndPartition, kafka.log.Log)) =&gt; Boolean)Iterable[(kafka.common.TopicAndPartition, kafka.log.Log)]">filterNot</span><span class="delimiter">(</span><span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span> =&gt; <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition)Boolean">contains</span><span class="delimiter">(</span><span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span>.<span title="=&gt; kafka.common.TopicAndPartition">_1</span><span class="delimiter">)</span><span class="delimiter">)</span> <span class="comment">// skip any logs already in-progress</span>
                          .<span title="(f: ((kafka.common.TopicAndPartition, kafka.log.Log)) =&gt; kafka.log.LogToClean)(implicit bf: scala.collection.generic.CanBuildFrom[Iterable[(kafka.common.TopicAndPartition, kafka.log.Log)],kafka.log.LogToClean,Iterable[kafka.log.LogToClean]])Iterable[kafka.log.LogToClean]">map</span><span title="scala.collection.generic.CanBuildFrom[scala.collection.Iterable.Coll,kafka.log.LogToClean,Iterable[kafka.log.LogToClean]]" class="delimiter">(</span><span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span> =&gt; <a href="LogCleaner.scala.html#kafka.log;LogToClean" title="(topicPartition: kafka.common.TopicAndPartition, log: kafka.log.Log, firstDirtyOffset: Long)kafka.log.LogToClean">LogToClean</a><span class="delimiter">(</span><span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span>.<span title="=&gt; kafka.common.TopicAndPartition">_1</span>, <span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span>.<span title="=&gt; kafka.log.Log">_2</span>,           <span class="comment">// create a LogToClean instance for each</span>
                                               <a href="#kafka.log;LogCleanerManager.grabFilthiestLog.lastClean" title="Map[kafka.common.TopicAndPartition,Long]">lastClean</a>.<span title="(key: kafka.common.TopicAndPartition, default: =&gt; Long)Long">getOrElse</span><span class="delimiter">(</span><span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span>.<span title="=&gt; kafka.common.TopicAndPartition">_1</span>, <span title="(kafka.common.TopicAndPartition, kafka.log.Log)">l</span>.<span title="=&gt; kafka.log.Log">_2</span>.<a href="Log.scala.html#kafka.log;Log.logSegments(b2658bab35)" title="=&gt; Iterable[kafka.log.LogSegment]">logSegments</a>.<span title="=&gt; kafka.log.LogSegment">head</span>.<a href="LogSegment.scala.html#kafka.log;LogSegment.baseOffset" title="=&gt; Long">baseOffset</a><span class="delimiter">)</span><span class="delimiter">)</span><span class="delimiter">)</span>
                          .<span title="(p: kafka.log.LogToClean =&gt; Boolean)Iterable[kafka.log.LogToClean]">filter</span><span class="delimiter">(</span><span title="kafka.log.LogToClean">l</span> =&gt; <span title="kafka.log.LogToClean">l</span>.<a href="LogCleaner.scala.html#kafka.log;LogToClean.totalBytes" title="=&gt; Long">totalBytes</a> <span title="(x: Int)Boolean">&gt;</span> <span title="Int(0)" class="int">0</span><span class="delimiter">)</span>             <span class="comment">// skip any empty logs</span>
      this.<a href="#kafka.log;LogCleanerManager.dirtiestLogCleanableRatio_=" title="(x$1: Double)Unit">dirtiestLogCleanableRatio</a> = if <span class="delimiter">(</span><span title="=&gt; Boolean">!</span><a href="#kafka.log;LogCleanerManager.grabFilthiestLog.dirtyLogs" title="Iterable[kafka.log.LogToClean]">dirtyLogs</a>.<span title="=&gt; Boolean">isEmpty</span><span class="delimiter">)</span> <a href="#kafka.log;LogCleanerManager.grabFilthiestLog.dirtyLogs" title="Iterable[kafka.log.LogToClean]">dirtyLogs</a>.<span title="(implicit cmp: Ordering[kafka.log.LogToClean])kafka.log.LogToClean">max</span>.<a href="LogCleaner.scala.html#kafka.log;LogToClean.cleanableRatio" title="=&gt; Double">cleanableRatio</a> else <span title="Double(0.0)" class="int">0</span>
      val <a title="Iterable[kafka.log.LogToClean]" id="kafka.log;LogCleanerManager.grabFilthiestLog.cleanableLogs">cleanableLogs</a> = <a href="#kafka.log;LogCleanerManager.grabFilthiestLog.dirtyLogs" title="Iterable[kafka.log.LogToClean]">dirtyLogs</a>.<span title="(p: kafka.log.LogToClean =&gt; Boolean)Iterable[kafka.log.LogToClean]">filter</span><span class="delimiter">(</span><a title="kafka.log.LogToClean" id="kafka.log;LogCleanerManager.grabFilthiestLog.cleanableLogs.$anonfun.l">l</a> =&gt; <a href="#kafka.log;LogCleanerManager.grabFilthiestLog.cleanableLogs.$anonfun.l" title="kafka.log.LogToClean">l</a>.<a href="LogCleaner.scala.html#kafka.log;LogToClean.cleanableRatio" title="=&gt; Double">cleanableRatio</a> <span title="(x: Double)Boolean">&gt;</span> <a href="#kafka.log;LogCleanerManager.grabFilthiestLog.cleanableLogs.$anonfun.l" title="kafka.log.LogToClean">l</a>.<a href="LogCleaner.scala.html#kafka.log;LogToClean.log" title="=&gt; kafka.log.Log">log</a>.<a href="Log.scala.html#kafka.log;Log.config" title="=&gt; kafka.log.LogConfig">config</a>.<a href="LogConfig.scala.html#kafka.log;LogConfig.minCleanableRatio" title="=&gt; Double">minCleanableRatio</a><span class="delimiter">)</span> <span class="comment">// and must meet the minimum threshold for dirty byte ratio</span>
      if<span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.grabFilthiestLog.cleanableLogs" title="Iterable[kafka.log.LogToClean]">cleanableLogs</a>.<span title="=&gt; Boolean">isEmpty</span><span class="delimiter">)</span> <span class="delimiter">{</span>
        <span title="None.type">None</span>
      <span class="delimiter">}</span> else <span class="delimiter">{</span>
        val <a title="kafka.log.LogToClean" id="kafka.log;LogCleanerManager.grabFilthiestLog.filthiest">filthiest</a> = <a href="#kafka.log;LogCleanerManager.grabFilthiestLog.cleanableLogs" title="Iterable[kafka.log.LogToClean]">cleanableLogs</a>.<span title="(implicit cmp: Ordering[kafka.log.LogToClean])kafka.log.LogToClean">max</span>
        <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition, value: kafka.log.LogCleaningState)Option[kafka.log.LogCleaningState]">put</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.grabFilthiestLog.filthiest" title="kafka.log.LogToClean">filthiest</a>.<a href="LogCleaner.scala.html#kafka.log;LogToClean.topicPartition" title="=&gt; kafka.common.TopicAndPartition">topicPartition</a>, <a href="#kafka.log.LogCleaningInProgress.readResolve" title="kafka.log.LogCleaningInProgress.type">LogCleaningInProgress</a><span class="delimiter">)</span>
        <span title="(x: kafka.log.LogToClean)Some[kafka.log.LogToClean]">Some</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.grabFilthiestLog.filthiest" title="kafka.log.LogToClean">filthiest</a><span class="delimiter">)</span>
      <span class="delimiter">}</span>
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>

  <span class="comment">/**
   *  Abort the cleaning of a particular partition, if it's in progress. This call blocks until the cleaning of
   *  the partition is aborted.
   *  This is implemented by first abortAndPausing and then resuming the cleaning of the partition.
   */</span>
  def <a title="(topicAndPartition: kafka.common.TopicAndPartition)Unit" id="kafka.log;LogCleanerManager.abortCleaning">abortCleaning</a><span class="delimiter">(</span><a title="kafka.common.TopicAndPartition" id="kafka.log;LogCleanerManager.abortCleaning.topicAndPartition">topicAndPartition</a>: <a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a><span class="delimiter">)</span> <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Unit)Unit">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span class="delimiter">{</span>
      <a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning" title="(topicAndPartition: kafka.common.TopicAndPartition)Unit">abortAndPauseCleaning</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span>
      <a href="#kafka.log;LogCleanerManager.resumeCleaning" title="(topicAndPartition: kafka.common.TopicAndPartition)Unit">resumeCleaning</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span>
      <a href="../utils/Logging.scala.html#kafka.utils;Logging.info(1729dbc42f)" title="(msg: =&gt; String)Unit">info</a><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;The cleaning for partition %s is aborted&quot;</span>.<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span><span class="delimiter">)</span>
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>

  <span class="comment">/**
   *  Abort the cleaning of a particular partition if it's in progress, and pause any future cleaning of this partition.
   *  This call blocks until the cleaning of the partition is aborted and paused.
   *  1. If the partition is not in progress, mark it as paused.
   *  2. Otherwise, first mark the state of the partition as aborted.
   *  3. The cleaner thread checks the state periodically and if it sees the state of the partition is aborted, it
   *     throws a LogCleaningAbortedException to stop the cleaning task.
   *  4. When the cleaning task is stopped, doneCleaning() is called, which sets the state of the partition as paused.
   *  5. abortAndPauseCleaning() waits until the state of the partition is changed to paused.
   */</span>
  def <a title="(topicAndPartition: kafka.common.TopicAndPartition)Unit" id="kafka.log;LogCleanerManager.abortAndPauseCleaning">abortAndPauseCleaning</a><span class="delimiter">(</span><a title="kafka.common.TopicAndPartition" id="kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition">topicAndPartition</a>: <a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a><span class="delimiter">)</span> <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Unit)Unit">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span class="delimiter">{</span>
      <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition)Option[kafka.log.LogCleaningState]">get</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span> match <span class="delimiter">{</span>
        case <span title="None.type">None</span> =&gt;
          <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition, value: kafka.log.LogCleaningState)Option[kafka.log.LogCleaningState]">put</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log.LogCleaningPaused.readResolve" title="kafka.log.LogCleaningPaused.type">LogCleaningPaused</a><span class="delimiter">)</span>
        case Some<span class="delimiter">(</span><a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.abortAndPauseCleaning.state">state</a><span class="delimiter">)</span> =&gt;
          <a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.state" title="kafka.log.LogCleaningState">state</a> match <span class="delimiter">{</span>
            case <a href="#kafka.log.LogCleaningInProgress.readResolve" title="kafka.log.LogCleaningInProgress.type">LogCleaningInProgress</a> =&gt;
              <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition, value: kafka.log.LogCleaningState)Option[kafka.log.LogCleaningState]">put</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log.LogCleaningAborted.readResolve" title="kafka.log.LogCleaningAborted.type">LogCleaningAborted</a><span class="delimiter">)</span>
            case <a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.abortAndPauseCleaning.s">s</a> =&gt;
              throw new <span title="IllegalStateException">IllegalStateException</span><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;Compaction for partition %s cannot be aborted and paused since it is in %s state.&quot;</span>
                                              .<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.s" title="kafka.log.LogCleaningState">s</a><span class="delimiter">)</span><span class="delimiter">)</span>
          <span class="delimiter">}</span>
      <span class="delimiter">}</span>
      while <span class="delimiter">(</span><span title="=&gt; Boolean">!</span><a href="#kafka.log;LogCleanerManager.isCleaningInState" title="(topicAndPartition: kafka.common.TopicAndPartition, expectedState: kafka.log.LogCleaningState)Boolean">isCleaningInState</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log.LogCleaningPaused.readResolve" title="kafka.log.LogCleaningPaused.type">LogCleaningPaused</a><span class="delimiter">)</span><span class="delimiter">)</span>
        <a href="#kafka.log;LogCleanerManager.pausedCleaningCond" title="=&gt; java.util.concurrent.locks.Condition">pausedCleaningCond</a>.<span title="(x$1: Long, x$2: java.util.concurrent.TimeUnit)Boolean">await</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.while$1" title="()Unit" class="delimiter">(</a><span title="Long(100L)" class="int">100</span>, TimeUnit.<span title="java.util.concurrent.TimeUnit(MILLISECONDS)">MILLISECONDS</span><span class="delimiter">)</span>
      <a href="../utils/Logging.scala.html#kafka.utils;Logging.info(1729dbc42f)" title="(msg: =&gt; String)Unit">info</a><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;The cleaning for partition %s is aborted and paused&quot;</span>.<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.abortAndPauseCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span><span class="delimiter">)</span>
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>

  <span class="comment">/**
   *  Resume the cleaning of a paused partition. This call blocks until the cleaning of a partition is resumed.
   */</span>
  def <a title="(topicAndPartition: kafka.common.TopicAndPartition)Unit" id="kafka.log;LogCleanerManager.resumeCleaning">resumeCleaning</a><span class="delimiter">(</span><a title="kafka.common.TopicAndPartition" id="kafka.log;LogCleanerManager.resumeCleaning.topicAndPartition">topicAndPartition</a>: <a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a><span class="delimiter">)</span> <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Option[kafka.log.LogCleaningState])Option[kafka.log.LogCleaningState]">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span class="delimiter">{</span>
      <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition)Option[kafka.log.LogCleaningState]">get</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.resumeCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span> match <span class="delimiter">{</span>
        case <span title="None.type">None</span> =&gt;
          throw new <span title="IllegalStateException">IllegalStateException</span><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;Compaction for partition %s cannot be resumed since it is not paused.&quot;</span>
                                          .<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.resumeCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span><span class="delimiter">)</span>
        case Some<span class="delimiter">(</span><a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.resumeCleaning.state">state</a><span class="delimiter">)</span> =&gt;
          <a href="#kafka.log;LogCleanerManager.resumeCleaning.state" title="kafka.log.LogCleaningState">state</a> match <span class="delimiter">{</span>
            case <a href="#kafka.log.LogCleaningPaused.readResolve" title="kafka.log.LogCleaningPaused.type">LogCleaningPaused</a> =&gt;
              <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition)Option[kafka.log.LogCleaningState]">remove</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.resumeCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span>
            case <a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.resumeCleaning.s">s</a> =&gt;
              throw new <span title="IllegalStateException">IllegalStateException</span><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;Compaction for partition %s cannot be resumed since it is in %s state.&quot;</span>
                                              .<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.resumeCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log;LogCleanerManager.resumeCleaning.s" title="kafka.log.LogCleaningState">s</a><span class="delimiter">)</span><span class="delimiter">)</span>
          <span class="delimiter">}</span>
      <span class="delimiter">}</span>
    <span class="delimiter">}</span>
    <a href="../utils/Logging.scala.html#kafka.utils;Logging.info(1729dbc42f)" title="(msg: =&gt; String)Unit">info</a><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;Compaction for partition %s is resumed&quot;</span>.<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.resumeCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span><span class="delimiter">)</span>
  <span class="delimiter">}</span>

  <span class="comment">/**
   *  Check if the cleaning for a partition is in a particular state. The caller is expected to hold lock while making the call.
   */</span>
  def <a title="(topicAndPartition: kafka.common.TopicAndPartition, expectedState: kafka.log.LogCleaningState)Boolean" id="kafka.log;LogCleanerManager.isCleaningInState">isCleaningInState</a><span class="delimiter">(</span><a title="kafka.common.TopicAndPartition" id="kafka.log;LogCleanerManager.isCleaningInState.topicAndPartition">topicAndPartition</a>: <a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a>, <a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.isCleaningInState.expectedState">expectedState</a>: <a href="#kafka.log;LogCleaningState" title="kafka.log.LogCleaningState">LogCleaningState</a><span class="delimiter">)</span>: <span title="Boolean">Boolean</span> = <span class="delimiter">{</span>
    <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition)Option[kafka.log.LogCleaningState]">get</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.isCleaningInState.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span> match <span class="delimiter">{</span>
      case <span title="None.type">None</span> =&gt; return false
      case Some<span class="delimiter">(</span><a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.isCleaningInState.state">state</a><span class="delimiter">)</span> =&gt;
        if <span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.isCleaningInState.state" title="kafka.log.LogCleaningState">state</a> <span title="(x$1: Any)Boolean">==</span> <a href="#kafka.log;LogCleanerManager.isCleaningInState.expectedState" title="kafka.log.LogCleaningState">expectedState</a><span class="delimiter">)</span>
          return true
        else
          return false
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>

  <span class="comment">/**
   *  Check if the cleaning for a partition is aborted. If so, throw an exception.
   */</span>
  def <a title="(topicAndPartition: kafka.common.TopicAndPartition)Unit" id="kafka.log;LogCleanerManager.checkCleaningAborted">checkCleaningAborted</a><span class="delimiter">(</span><a title="kafka.common.TopicAndPartition" id="kafka.log;LogCleanerManager.checkCleaningAborted.topicAndPartition">topicAndPartition</a>: <a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a><span class="delimiter">)</span> <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Unit)Unit">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span class="delimiter">{</span>
      if <span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.isCleaningInState" title="(topicAndPartition: kafka.common.TopicAndPartition, expectedState: kafka.log.LogCleaningState)Boolean">isCleaningInState</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.checkCleaningAborted.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log.LogCleaningAborted.readResolve" title="kafka.log.LogCleaningAborted.type">LogCleaningAborted</a><span class="delimiter">)</span><span class="delimiter">)</span>
        throw new <a href="../common/LogCleaningAbortedException.scala.html#kafka.common;LogCleaningAbortedException" title="kafka.common.LogCleaningAbortedException">LogCleaningAbortedException</a><span class="delimiter">(</span><span class="delimiter">)</span>
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>

  def <a title="(dataDir: java.io.File, update: Option[(kafka.common.TopicAndPartition, Long)])Unit" id="kafka.log;LogCleanerManager.updateCheckpoints">updateCheckpoints</a><span class="delimiter">(</span><a title="java.io.File" id="kafka.log;LogCleanerManager.updateCheckpoints.dataDir">dataDir</a>: <span title="java.io.File">File</span>, <a title="Option[(kafka.common.TopicAndPartition, Long)]" id="kafka.log;LogCleanerManager.updateCheckpoints.update">update</a>: <span title="Option[(kafka.common.TopicAndPartition, Long)]">Option</span><span class="delimiter">[</span><span class="delimiter">(</span>TopicAndPartition,Long<span class="delimiter">)</span><span class="delimiter">]</span><span class="delimiter">)</span> <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Unit)Unit">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span class="delimiter">{</span>
      val <a title="kafka.server.OffsetCheckpoint" id="kafka.log;LogCleanerManager.updateCheckpoints.checkpoint">checkpoint</a> = <a href="#kafka.log;LogCleanerManager.checkpoints" title="(key: java.io.File)kafka.server.OffsetCheckpoint">checkpoints</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.updateCheckpoints.dataDir" title="java.io.File">dataDir</a><span class="delimiter">)</span>
      val existing = <a href="#kafka.log;LogCleanerManager.updateCheckpoints.checkpoint" title="kafka.server.OffsetCheckpoint">checkpoint</a>.<a href="../server/OffsetCheckpoint.scala.html#kafka.server;OffsetCheckpoint.read" title="()scala.collection.Map[kafka.common.TopicAndPartition,Long]">read</a><span class="delimiter">(</span><span class="delimiter">)</span>.<span title="(p: kafka.common.TopicAndPartition =&gt; Boolean)scala.collection.Map[kafka.common.TopicAndPartition,Long]">filterKeys</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.logs" title="=&gt; kafka.utils.Pool[kafka.common.TopicAndPartition,kafka.log.Log]">logs</a>.<a href="../utils/Pool.scala.html#kafka.utils;Pool.keys" title="=&gt; scala.collection.mutable.Set[kafka.common.TopicAndPartition]">keys</a><span class="delimiter">)</span> <a title="scala.collection.Map[kafka.common.TopicAndPartition,Long]" id="kafka.log;LogCleanerManager.updateCheckpoints.existing">++</a> <a href="#kafka.log;LogCleanerManager.updateCheckpoints.update" title="(xo: Option[(kafka.common.TopicAndPartition, Long)])Iterable[(kafka.common.TopicAndPartition, Long)]">update</a>
      <a href="#kafka.log;LogCleanerManager.updateCheckpoints.checkpoint" title="kafka.server.OffsetCheckpoint">checkpoint</a>.<a href="../server/OffsetCheckpoint.scala.html#kafka.server;OffsetCheckpoint.write" title="(offsets: scala.collection.Map[kafka.common.TopicAndPartition,Long])Unit">write</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.updateCheckpoints.existing" title="scala.collection.Map[kafka.common.TopicAndPartition,Long]">existing</a><span class="delimiter">)</span>
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>

  <span class="comment">/**
   * Save out the endOffset and remove the given log from the in-progress set, if not aborted.
   */</span>
  def <a title="(topicAndPartition: kafka.common.TopicAndPartition, dataDir: java.io.File, endOffset: Long)Unit" id="kafka.log;LogCleanerManager.doneCleaning">doneCleaning</a><span class="delimiter">(</span><a title="kafka.common.TopicAndPartition" id="kafka.log;LogCleanerManager.doneCleaning.topicAndPartition">topicAndPartition</a>: <a href="../common/TopicAndPartition.scala.html#kafka.common;TopicAndPartition" title="kafka.common.TopicAndPartition">TopicAndPartition</a>, <a title="java.io.File" id="kafka.log;LogCleanerManager.doneCleaning.dataDir">dataDir</a>: <span title="java.io.File">File</span>, <a title="Long" id="kafka.log;LogCleanerManager.doneCleaning.endOffset">endOffset</a>: <span title="Long">Long</span><span class="delimiter">)</span> <span class="delimiter">{</span>
    <a href="../utils/Utils.scala.html#kafka.utils.Utils.inLock" title="(lock: java.util.concurrent.locks.Lock)(fun: =&gt; Any)Any">inLock</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.lock" title="=&gt; java.util.concurrent.locks.ReentrantLock">lock</a><span class="delimiter">)</span> <span title="Unit" class="delimiter">{</span>
      <a href="#kafka.log;LogCleanerManager.inProgress" title="(key: kafka.common.TopicAndPartition)kafka.log.LogCleaningState">inProgress</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.doneCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span> match <span class="delimiter">{</span>
        case <a href="#kafka.log.LogCleaningInProgress.readResolve" title="kafka.log.LogCleaningInProgress.type">LogCleaningInProgress</a> =&gt;
          <a href="#kafka.log;LogCleanerManager.updateCheckpoints" title="(dataDir: java.io.File, update: Option[(kafka.common.TopicAndPartition, Long)])Unit">updateCheckpoints</a><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.doneCleaning.dataDir" title="java.io.File">dataDir</a>,<span title="(x: (kafka.common.TopicAndPartition, Long))Option[(kafka.common.TopicAndPartition, Long)]">Option</span><span title="(_1: kafka.common.TopicAndPartition, _2: Long)(kafka.common.TopicAndPartition, Long)" class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.doneCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log;LogCleanerManager.doneCleaning.endOffset" title="Long">endOffset</a><span class="delimiter">)</span><span class="delimiter">)</span>
          <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition)Option[kafka.log.LogCleaningState]">remove</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.doneCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a><span class="delimiter">)</span>
        case <a href="#kafka.log.LogCleaningAborted.readResolve" title="kafka.log.LogCleaningAborted.type">LogCleaningAborted</a> =&gt;
          <a href="#kafka.log;LogCleanerManager.inProgress" title="=&gt; scala.collection.mutable.HashMap[kafka.common.TopicAndPartition,kafka.log.LogCleaningState]">inProgress</a>.<span title="(key: kafka.common.TopicAndPartition, value: kafka.log.LogCleaningState)Option[kafka.log.LogCleaningState]">put</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.doneCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log.LogCleaningPaused.readResolve" title="kafka.log.LogCleaningPaused.type">LogCleaningPaused</a><span class="delimiter">)</span>
          <a href="#kafka.log;LogCleanerManager.pausedCleaningCond" title="=&gt; java.util.concurrent.locks.Condition">pausedCleaningCond</a>.<span title="()Unit">signalAll</span><span class="delimiter">(</span><span class="delimiter">)</span>
        case <a title="kafka.log.LogCleaningState" id="kafka.log;LogCleanerManager.doneCleaning.s">s</a> =&gt;
          throw new <span title="IllegalStateException">IllegalStateException</span><span class="delimiter">(</span><span title="implicit scala.Predef.augmentString : (x: String)scala.collection.immutable.StringOps" class="string">&quot;In-progress partition %s cannot be in %s state.&quot;</span>.<span title="(args: Any*)String">format</span><span class="delimiter">(</span><a href="#kafka.log;LogCleanerManager.doneCleaning.topicAndPartition" title="kafka.common.TopicAndPartition">topicAndPartition</a>, <a href="#kafka.log;LogCleanerManager.doneCleaning.s" title="kafka.log.LogCleaningState">s</a><span class="delimiter">)</span><span class="delimiter">)</span>
      <span class="delimiter">}</span>
    <span class="delimiter">}</span>
  <span class="delimiter">}</span>
<span class="delimiter">}</span>

        </pre>
    </body>
</html>
